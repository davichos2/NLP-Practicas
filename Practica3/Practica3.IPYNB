{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Práctica 3. Extacción de palabras clave y resumen automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerias\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string\n",
    "from rake_nltk import Rake\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\F'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\F'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\davic\\AppData\\Local\\Temp\\ipykernel_16272\\2199434100.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  with open('libros\\The Adventures of Sherlock Holmes.txt' ,'r', encoding = 'utf-8') as archivo:\n",
      "C:\\Users\\davic\\AppData\\Local\\Temp\\ipykernel_16272\\2199434100.py:5: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  with open('libros\\The Last Man.txt' ,'r', encoding = 'utf-8') as archivo:\n",
      "C:\\Users\\davic\\AppData\\Local\\Temp\\ipykernel_16272\\2199434100.py:8: SyntaxWarning: invalid escape sequence '\\F'\n",
      "  with open('libros\\Frankenstein.txt' ,'r', encoding = 'utf-8') as archivo:\n",
      "C:\\Users\\davic\\AppData\\Local\\Temp\\ipykernel_16272\\2199434100.py:11: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  with open('libros\\The War of the Worlds.txt' ,'r', encoding = 'utf-8') as archivo:\n",
      "C:\\Users\\davic\\AppData\\Local\\Temp\\ipykernel_16272\\2199434100.py:14: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  with open('libros\\THE SECRET ADVERSARY.txt' ,'r', encoding = 'utf-8') as archivo:\n",
      "C:\\Users\\davic\\AppData\\Local\\Temp\\ipykernel_16272\\2199434100.py:17: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  with open('libros\\The Mysterious Affair at Styles.txt' ,'r', encoding = 'utf-8') as archivo:\n"
     ]
    }
   ],
   "source": [
    "#Cargar los documentos.\n",
    "with open('libros\\The Adventures of Sherlock Holmes.txt' ,'r', encoding = 'utf-8') as archivo:\n",
    "    libro1 = archivo.read()\n",
    "\n",
    "with open('libros\\The Last Man.txt' ,'r', encoding = 'utf-8') as archivo:\n",
    "    libro2 = archivo.read()\n",
    "\n",
    "with open('libros\\Frankenstein.txt' ,'r', encoding = 'utf-8') as archivo:\n",
    "    libro3 = archivo.read()\n",
    "\n",
    "with open('libros\\The War of the Worlds.txt' ,'r', encoding = 'utf-8') as archivo:\n",
    "    libro4 = archivo.read()\n",
    "\n",
    "with open('libros\\THE SECRET ADVERSARY.txt' ,'r', encoding = 'utf-8') as archivo:\n",
    "    libro5 = archivo.read()\n",
    "\n",
    "with open('libros\\The Mysterious Affair at Styles.txt' ,'r', encoding = 'utf-8') as archivo:\n",
    "    libro6 = archivo.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Frases más representativas con  TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['holmes', 'man', 'room', 'time', 'door']\n",
      "\n",
      "['raymond', 'life', 'heart', 'time', 'man']\n",
      "\n",
      "['man', 'father', 'life', 'eyes', 'time']\n",
      "\n",
      "['martians', 'people', 'man', 'time', 'men']\n",
      "\n",
      "['tuppence', 'tommy', 'julius', 'james', 'man']\n",
      "\n",
      "['poirot', 'inglethorp', 'john', 'room', 'mrs']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def top_Words(texto):\n",
    "    # Convertir a minúsculas y eliminar puntos\n",
    "    texto = texto.lower().replace('.', '') \n",
    "    #Tokenizar el texto\n",
    "    tokens = nltk.word_tokenize(texto)\n",
    "    #aplicar pos tagging\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    #Obtener solo sustantivos\n",
    "    nouns = [word for (word, tag) in tagged if tag.startswith(\"NN\")]\n",
    "    #Aplicar tf-idf\n",
    "    #En lugar de pasar el texto completo, se pasa solo los sustantivos\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform([\" \".join(nouns)])\n",
    "    #Obtener las palabras mas importantes\n",
    "    top_words = sorted( vectorizer.vocabulary_, key = lambda x: X[0,vectorizer.vocabulary_[x]], reverse= True)[:5]\n",
    "    #imprimir las palabras mas importantes\n",
    "    print(f\"{top_words}\\n\")\n",
    "\n",
    "#Remover indiceS\n",
    "libro1 = re.sub(r'Contents.*?(?=I.\\n)', '', libro1, flags=re.DOTALL)\n",
    "libro2 = re.sub(r'Contents.*?(?=I visited)', '', libro2, flags=re.DOTALL)\n",
    "libro3 = re.sub(r'CONTENTS.*?(?=England._\\n)', '', libro3, flags=re.DOTALL)\n",
    "libro4 = re.sub(r'But.*?(?=No one would)', '', libro4, flags=re.DOTALL)\n",
    "libro5 = re.sub(r'CONTENTS.*?AND AFTER', '', libro5, flags=re.DOTALL)\n",
    "libro6 = re.sub(r'Contents.*?(?=EXPLAINS\\n)', '', libro6, flags=re.DOTALL)\n",
    "\n",
    "top_Words(libro1)\n",
    "top_Words(libro2)\n",
    "top_Words(libro3)\n",
    "top_Words(libro4)\n",
    "top_Words(libro5)\n",
    "top_Words(libro6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Frases más representativas con rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ['said lestrade oct 4th rooms 8_s_ breakfast 2_s_ 6_d_ cocktail 1_s_ lunch 2_s_ 6_d_ glass sherry 8_d_', '_globe_ _star_ _pall mall_ _st jamess gazette_ _evening news_ _standard_ _echo_', 'year 1858 contraltohum la scala hum prima donna imperial opera', 'st augustine 9th mccauley cleared 10th john swain cleared 12th visited paramore', 'new zealand stock paying 4½ per cent two thousand five hundred pounds']\n",
      "\n",
      "\n",
      " ['di mie tenere frondi altro lavoro credea mostrarte e qual fero pianeta ne nvidiò insieme', 'cada flor costruye un monumento cada edificio es un sepulcro altivo cada soldado un esqueleto vivo3', 'human race 10 calderon de la barca 11 2 wordsworth 12 keats 13 andrew marvell 14', 'secluded life pareamo aver qui tutto il ben raccolto che fra mortali', 'obsequie18 16 wordsworth 17 priors solomon 18 clevelands poems vol iii chapter']\n",
      "\n",
      "\n",
      " ['affectionate brother r walton letter 2 _to mrs saville england_ archangel 28th march 17', 'affectionate brother robert walton letter 3 _to mrs saville england_ july 7th 17', 'beloved sister rw letter 4 _to mrs saville england_ august 5th 17', 'mary wollstonecraft godwin shelley england_ st petersburgh dec 11th 17', 'steel aright walton _in continuation_ august 26th 17']\n",
      "\n",
      "\n",
      " ['filthy colliers trim merchantmen cattle ships passenger boats petroleum tanks ocean tramps', 'crescent everywhereat staines hounslow ditton esher ockham behind hills', 'unfaithful city woe woe woe woe woe', 'cycles leanfaced unkempt scorched along every country lane shouting', 'desolated areaperhaps twenty square miles altogetherthat encircled']\n",
      "\n",
      "\n",
      " ['eminent physician recommends unlimited _hors dœuvre_ lobster _à laméricane_ chicken newberg', 'could ive touted round ive answered advertisements ive tried every mortal blessed thing ive screwed', '_find jane finn_ yes butwho _is_ jane finn mr carter nodded gravely yes youre entitled', 'sincere friend mr carter tuppences spirits rose mercurially mr carters warnings passed unheeded', 'read 20 south audley mansions miss wheeler 43 clapington road battersea shes']\n",
      "\n",
      "\n",
      " ['text books strychninae sulph 1 gr potass bromide 3vi aqua ad 3viii fiat mistura _this solution deposits', 'extremely expressive grimace darling alfreddearest alfredwicked calumnies wicked lieswicked womanto accuse', 'excitement mademoiselle dorcas mademoiselle dorcas _un moment sil vous plaît_ dorcas quite flurried', 'telegraphic style weeds grow like house afire cant keep even', 'answer yessir mumbled manning poirot stepped forward briskly mannings eye swept']\n"
     ]
    }
   ],
   "source": [
    "rake_nltk_var = Rake()\n",
    "\n",
    "def top_Words_rake(texto):\n",
    "    #Remover caracteres especiales\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
    "    #Remover saltos de linea\n",
    "    texto = texto.replace('\\n', ' ')\n",
    "    #Extraer las palabras clave\n",
    "    rake_nltk_var.extract_keywords_from_text(texto)\n",
    "    keyword_extracted = rake_nltk_var.get_ranked_phrases()\n",
    "    #Imprimir las palabras clave\n",
    "    print(f\"\\n\\n {keyword_extracted[:5]}\")\n",
    "\n",
    "top_Words_rake(libro1)\n",
    "top_Words_rake(libro2)\n",
    "top_Words_rake(libro3)\n",
    "top_Words_rake(libro4)\n",
    "top_Words_rake(libro5)\n",
    "top_Words_rake(libro6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Frases mas representativas con BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\davic\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (51210 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ['signs', 'experiences', 'powers', 'royal', 'sex']\n",
      "\n",
      "\n",
      " ['preservation', 'persisted', 'companion', 'return', 'surrounding']\n",
      "\n",
      "\n",
      " ['composed', 'march', 'dec', 'tread', 'di']\n",
      "\n",
      "\n",
      " ['heat', 'men', 'ceased', 'un', 'bison']\n",
      "\n",
      "\n",
      " ['chance', 'hear', 'don', 'know', 'pm']\n",
      "\n",
      "\n",
      " ['lawrence', 'came', 'possessed', 'subsided', 'regularly']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def top_Words_bert(texto):\n",
    "    tokens = tokenizer.encode(texto, add_special_tokens=True, return_tensors='pt')\n",
    "\n",
    "    # Dividir el texto en segmentos más pequeños\n",
    "    max_segment_len = 512 \n",
    "    num_segments = (tokens.size(1) - 2) // max_segment_len + 1\n",
    "    segment_embeddings = []\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * max_segment_len\n",
    "        end_idx = min((i + 1) * max_segment_len, tokens.size(1))\n",
    "        segment_tokens = tokens[:, start_idx:end_idx]\n",
    "\n",
    "        # Obtener las representaciones de palabras contextualizadas\n",
    "        with torch.no_grad():\n",
    "            outputs = model(segment_tokens)\n",
    "            word_embeddings = outputs.last_hidden_state\n",
    "\n",
    "        # Promediar las representaciones de palabras para obtener una representación de segmento\n",
    "        segment_embedding = torch.mean(word_embeddings, dim=1).squeeze()\n",
    "        segment_embeddings.append(segment_embedding)\n",
    "\n",
    "    # Concatenar las representaciones de segmento y promediarlas para obtener una representación de oración global\n",
    "    sentence_embedding = torch.mean(torch.stack(segment_embeddings), dim=0)\n",
    "\n",
    "    top_words = []\n",
    "    for word_idx in torch.topk(sentence_embedding, 10).indices:\n",
    "        word = tokenizer.decode([tokens[0, word_idx]])\n",
    "        if not word.startswith('#' or '...' or '!' or ';'):\n",
    "            top_words.append(word)\n",
    "    #Imprimir las  5 palabras mas importantes \n",
    "    print(f\"\\n\\n {top_words[:5]}\")\n",
    "    \n",
    "\n",
    "\n",
    "#Funcion para remover signos de puntuacion y stopwords\n",
    "def remove_punctuation_stopwords(text):\n",
    "    # Remover signos de puntuación\n",
    "    patron = re.compile(r'[#,\\-_.;:‘’!¿?\"”]+')\n",
    "    text = patron.sub('', text)\n",
    "    # Remover stopwords\n",
    "    text = ' '.join([word for word in text.split() if word.lower() not in STOP_WORDS])\n",
    "    top_Words_bert(text)\n",
    "\n",
    "remove_punctuation_stopwords(libro1)\n",
    "remove_punctuation_stopwords(libro2)\n",
    "remove_punctuation_stopwords(libro3)\n",
    "remove_punctuation_stopwords(libro4)\n",
    "remove_punctuation_stopwords(libro5)\n",
    "remove_punctuation_stopwords(libro6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Frases más representativas con Textrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "\"They were admirable things for the observer—excellent for\n",
      "drawing the veil from men’s motives and actions.\" ,\n",
      "\n",
      "\"He was pacing the room swiftly, eagerly, with his\n",
      "head sunk upon his chest and his hands clasped behind him.\" ,\n",
      "\n",
      "\"What do you deduce from\n",
      "it?”\n",
      "\n",
      "I carefully examined the writing, and the paper upon which it was\n",
      "written.\n",
      "\n",
      "\" ,\n",
      "\n",
      "\"His eyes sparkled, and he sent up a great blue triumphant cloud\n",
      "from his cigarette.\n",
      "\n",
      "\" ,\n",
      "\n",
      "\"A man entered who could hardly have been less than six feet six inches\n",
      "in height, with the chest and limbs of a Hercules.\" ,\n",
      "\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\"We passed\n",
      "by a natural archway, leading to a second gallery, and enquired, if we\n",
      "could not enter there also.\" ,\n",
      "\n",
      "\"Shall I go alone, or will you accompany me?”\n",
      "\n",
      "I signified my readiness to proceed, but our guides protested against\n",
      "such a measure.\" ,\n",
      "\n",
      "\"On\n",
      "examination, we found that all the leaves, bark, and other substances,\n",
      "were traced with written characters.\" ,\n",
      "\n",
      "\"Scattered and unconnected as they were, I have been obliged to\n",
      "add links, and model the work into a consistent form.\" ,\n",
      "\n",
      "\"He was induced\n",
      "to look with extreme disapprobation, and at last with distaste, on my\n",
      "father’s imprudence and follies.\" ,\n",
      "\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\"This breeze, which has travelled from the regions towards\n",
      "which I am advancing, gives me a foretaste of those icy climes.\n",
      "\" ,\n",
      "\n",
      "\"Yet\n",
      "some feelings, unallied to the dross of human nature, beat even in these\n",
      "rugged bosoms.\" ,\n",
      "\n",
      "\"The master is a person of an excellent disposition and is remarkable in the\n",
      "ship for his gentleness and the mildness of his discipline.\" ,\n",
      "\n",
      "\"This\n",
      "circumstance, added to his well-known integrity and dauntless courage, made\n",
      "me very desirous to engage him.\" ,\n",
      "\n",
      "\"We were, as we believed,\n",
      "many hundred miles from any land; but this apparition seemed to denote that\n",
      "it was not, in reality, so distant as we had supposed.\" ,\n",
      "\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\"The immediate pressure of necessity has brightened\n",
      "their intellects, enlarged their powers, and hardened their hearts.\" ,\n",
      "\n",
      "\"Few people realise the immensity of vacancy in which the dust of\n",
      "the material universe swims.\n",
      "\n",
      "\" ,\n",
      "\n",
      "\"I remember how I sat on the table there in the blackness, with\n",
      "patches of green and crimson swimming before my eyes.\" ,\n",
      "\n",
      "\"Ogilvy watched till\n",
      "one, and then gave it up; and we lit the lantern and walked over to his\n",
      "house.\" ,\n",
      "\n",
      "\"He pointed out to me how unlikely it was that organic\n",
      "evolution had taken the same direction in the two adjacent planets.\n",
      "\n",
      "\" ,\n",
      "\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\"Some still clung\n",
      "desperately to husbands and fathers; others clutched their children\n",
      "closely to their breasts.\" ,\n",
      "\n",
      "\"Then\n",
      "aloud he said abruptly: “You are an American?”\n",
      "\n",
      "“Yes.”\n",
      "\n",
      "“A patriotic one?”\n",
      "\n",
      "\" ,\n",
      "\n",
      "\"Is\n",
      "that clear?”\n",
      "\n",
      "“Quite clear.”\n",
      "\n",
      "“Then be ready--I’m going to say good-bye.”\" ,\n",
      "\n",
      "\"In answer\n",
      "to a quick command, the girl went forward to take her place in the boat.\n",
      "\n",
      "\n",
      "\n",
      "\" ,\n",
      "\n",
      "\"The place was full, and they wandered about looking for a table,\n",
      "catching odds and ends of conversation as they did so.\n",
      "\n",
      "\" ,\n",
      "\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\"Having no near relations or friends, I was trying to make\n",
      "up my mind what to do, when I ran across John Cavendish.\" ,\n",
      "\n",
      "\"John noticed my surprise at the news of his mother’s remarriage and\n",
      "smiled rather ruefully.\n",
      "\n",
      "\" ,\n",
      "\n",
      "\"He’s got a great black beard,\n",
      "and wears patent leather boots in all weathers!\" ,\n",
      "\n",
      "\"But you could have knocked us\n",
      "all down with a feather when, three months ago, she suddenly announced\n",
      "that she and Alfred were engaged!\" ,\n",
      "\n",
      "\"She\n",
      "works in the Red Cross Hospital at Tadminster, seven miles away.”\n",
      "\n",
      "\" ,\n",
      "\n",
      "\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo de idioma\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Función para extraer frases clave usando TextRank\n",
    "def top_words_spacy(text, max_phrase_length=10):\n",
    "    # Procesar el texto con spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Construir una lista de oraciones\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    \n",
    "    # Calcular el puntaje de TextRank para cada oración\n",
    "    wordsSpacy = []\n",
    "    for sent in sentences:\n",
    "        phrase_doc = nlp(sent)\n",
    "        phrase_tokens = [token.text for token in phrase_doc if not token.is_stop and not token.is_punct]\n",
    "        if len(phrase_tokens) <= max_phrase_length:\n",
    "            wordsSpacy.append((sent, len(phrase_tokens)))\n",
    "    \n",
    "    # Ordenar las frases clave por puntaje de TextRank\n",
    "    wordsSpacy = sorted(wordsSpacy, key=lambda x: x[1], reverse=True)\n",
    "    #Imprimir las frases clave\n",
    "    print(\"[\")\n",
    "    for frase, _ in wordsSpacy[:5]:\n",
    "        print(f\"\\\"{frase}\\\" ,\\n\")\n",
    "    print(\"\\n]\\n\")\n",
    "\n",
    "\n",
    "top_words_spacy(libro1)\n",
    "top_words_spacy(libro2)\n",
    "top_words_spacy(libro3)\n",
    "top_words_spacy(libro4)\n",
    "top_words_spacy(libro5)\n",
    "top_words_spacy(libro6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Resumen con Frecuencia de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen:\n",
      "Go visit the Prairies in June,\n",
      "when for scores on scores of miles you wade knee-deep among\n",
      "Tiger-lilies—what is the one charm wanting?—Water—there is not a drop\n",
      "of water there! And more than all, if\n",
      "just previous to putting your hand into the tar-pot, you have been\n",
      "lording it as a country schoolmaster, making the tallest boys stand in\n",
      "awe of you. Its extreme\n",
      "downtown is the battery, where that noble mole is washed by waves, and\n",
      "cooled by breezes, which a few hours previous were out of sight of\n",
      "land. No, when I go to sea, I go as a simple sailor, right before the mast,\n",
      "plumb down into the forecastle, aloft there to the royal mast-head. There now is your insular city of the Manhattoes, belted round by\n",
      "wharves as Indian isles by coral reefs—commerce surrounds it with her\n",
      "surf. But these\n",
      "are all landsmen; of week days pent up in lath and plaster—tied to\n",
      "counters, nailed to benches, clinched to desks. Why is almost every robust healthy boy with a\n",
      "robust healthy soul in him, at some time or other crazy to go to sea? If they\n",
      "but knew it, almost all men in their degree, some time or other,\n",
      "cherish very nearly the same feelings towards the ocean with me. What\n",
      "do you see?—Posted like silent sentinels all around the town, stand\n",
      "thousands upon thousands of mortal men fixed in ocean reveries. And,\n",
      "doubtless, my going on this whaling voyage, formed part of the grand\n",
      "programme of Providence that was drawn up a long time ago.\n",
      "\n",
      "\n",
      "Resumen:\n",
      "Do cats eat bats?” and\n",
      "sometimes, “Do bats eat cats?” for, you see, as she couldn’t answer\n",
      "either question, it didn’t much matter which way she put it. *      *\n",
      "\n",
      "\n",
      "“What a curious feeling!” said Alice; “I must be shutting up like a\n",
      "telescope.” And here\n",
      "Alice began to get rather sleepy, and went on saying to herself, in a\n",
      "dreamy sort of way, “Do cats eat bats? There was nothing so _very_ remarkable in that; nor did Alice think it\n",
      "so _very_ much out of the way to hear the Rabbit say to itself, “Oh\n",
      "dear! no one listening, this time, as it didn’t sound at all\n",
      "the right word) “—but I shall have to ask them what the name of the\n",
      "country is, you know. For, you see, so many out-of-the-way things had\n",
      "happened lately, that Alice had begun to think that very few things\n",
      "indeed were really impossible. And she tried to fancy what the\n",
      "flame of a candle is like after the candle is blown out, for she could\n",
      "not remember ever having seen such a thing. Please, Ma’am, is this New Zealand or Australia?”\n",
      "(and she tried to curtsey as she spoke—fancy _curtseying_ as you’re\n",
      "falling through the air! (Alice had no\n",
      "idea what Latitude was, or Longitude either, but thought they were nice\n",
      "grand words to say.) There are\n",
      "no mice in the air, I’m afraid, but you might catch a bat, and that’s\n",
      "very like a mouse, you know.\n"
     ]
    }
   ],
   "source": [
    "def resumenF(texto):\n",
    "    doc = nlp(texto)\n",
    "\n",
    "    tokens = [token.text for token in doc]\n",
    "\n",
    "    # Eliminar palabras vacías y signos de puntuación\n",
    "    word_frequencies = {}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in stopwords:\n",
    "            if word.text.lower() not in string.punctuation:\n",
    "                # Contar las frecuencias de las palabras\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "\n",
    "    max_frequency = max(word_frequencies.values())\n",
    "\n",
    "    # Normalizar las frecuencias de las palabras\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = word_frequencies[word]/max_frequency\n",
    "\n",
    "    sentence_list = [ sentence for sentence in doc.sents ]\n",
    "\n",
    "    # Calcular los puntajes de las frases\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_list:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if len(sent.text.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "\n",
    "\n",
    "    # Ordenar las frases según sus puntajes de evaluación\n",
    "    top_sentences = sorted(sentence_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    # Concatenar las frases seleccionadas en un solo párrafo\n",
    "    summary = \" \".join([sentence.text.strip() for sentence, score in top_sentences])\n",
    "\n",
    "    # Imprimir el resumen\n",
    "    print(\"Resumen:\")\n",
    "    print(summary)\n",
    "\n",
    "\n",
    "#Cargar los libros para los resumenes\n",
    "with open('libros/MOBY-DICK;.txt' ,'r', encoding = 'utf-8') as archivo:\n",
    "    libro7 = archivo.read()\n",
    "\n",
    "with open('libros/Alice’s Adventures in Wonderland.txt', 'r', encoding = 'utf-8') as archivo:\n",
    "    libro8 = archivo.read()\n",
    "\n",
    "\n",
    "stopwords = list(STOP_WORDS)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#Limpiar los libros (remover indices y recuperar el primer capitulo.)\n",
    "libro7 = re.sub(r'CONTENTS.*?(?=Call me Ishmael)', '', libro7, flags=re.DOTALL)\n",
    "patron = re.compile(r\"Call me Ishmael(.*?)CHAPTER 2\", re.DOTALL)\n",
    "resultado = patron.search(libro7)\n",
    "\n",
    "libro8 = re.sub(r'THE MILLENNIUM FULCRUM EDITION 3\\.0.*?(?=Alice was)', '', libro8, flags= re.DOTALL)\n",
    "patron = re.compile(r\"Alice was.*?CHAPTER II\", re.DOTALL)\n",
    "resultado2 = patron.search(libro8)\n",
    "\n",
    "resumenF(resultado.group(0))\n",
    "print(\"\\n\")\n",
    "resumenF(resultado2.group(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Resumen con Textrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen:\n",
      "Though I cannot tell why it was exactly that those stage managers, the Fates, put me down for this shabby part of a whaling voyage, when others were set down for magnificent parts in high tragedies, and short and easy parts in genteel comedies, and jolly parts in farces—though I cannot tell why this was exactly; yet, now that I recall all the circumstances, I think I can see a little into the springs and motives which being cunningly presented to me under various disguises, induced me to set about performing the part I did, besides cajoling me into the delusion that it was a choice resulting from my own unbiased freewill and discriminating judgment. By reason of these things, then, the whaling voyage was welcome; the great flood-gates of the wonder-world swung open, and in the wild conceits that swayed me to my purpose, two and two there floated into my inmost soul, endless processions of the whale, and, mid most of them all, one grand hooded phantom, like a snow hill in the air. Whenever I find myself growing grim about the mouth; whenever it is a damp, drizzly November in my soul; whenever I find myself involuntarily pausing before coffin warehouses, and bringing up the rear of every funeral I meet; and especially whenever my hypos get such an upper hand of me, that it requires a strong moral principle to prevent me from deliberately stepping into the street, and methodically knocking people’s hats off—then, I account it high time to get to sea as soon as I can. Well, then, however the old sea-captains may order me about—however they may thump and punch me about, I have the satisfaction of knowing that it is all right; that everybody else is one way or other served in much the same way—either in a physical or metaphysical point of view, that is; and so the universal thump is passed round, and all hands should rub each other’s shoulder-blades, and be content. But wherefore it was that after having repeatedly smelt the sea as a merchant sailor, I should now take it into my head to go on a whaling voyage; this the invisible police officer of the Fates, who has the constant surveillance of me, and secretly dogs me, and influences me in some unaccountable way—he can better answer than any one else. Now, when I say that I am in the habit of going to sea whenever I begin to grow hazy about the eyes, and begin to be over conscious of my lungs, I do not mean to have it inferred that I ever go to sea as a passenger. The transition is a keen one, I assure you, from a schoolmaster to a sailor, and requires a strong decoction of Seneca and the Stoics to enable you to grin and bear it. And as for going as cook,—though I confess there is considerable glory in that, a cook being a sort of officer on ship-board—yet, somehow, I never fancied broiling fowls;—though once broiled, judiciously buttered, and judgmatically salted and peppered, there is no one who will speak more respectfully, not to say reverentially, of a broiled fowl than I will. Then the wild and distant seas where he rolled his island bulk; the undeliverable, nameless perils of the whale; these, with all the attending marvels of a thousand Patagonian sights and sounds, helped to sway me to my wish. For as in this world, head winds are far more prevalent than winds from astern (that is, if you never violate the Pythagorean maxim), so for the most part the Commodore on the quarter-deck gets his atmosphere at second hand from the sailors on the forecastle.\n",
      "\n",
      "\n",
      "Resumen:\n",
      "I shall be late!” (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually _took a watch out of its waistcoat-pocket_, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge. when she got to the door, she found she had forgotten the little golden key, and when she went back to the table for it, she found she could not possibly reach it: she could see it quite plainly through the glass, and she tried her best to climb up one of the legs of the table, but it was too slippery; and when she had tired herself out with trying, the poor little thing sat down and cried. There was not a moment to be lost: away went Alice like the wind, and was just in time to hear it say, as it turned a corner, “Oh my ears and whiskers, how late it’s getting!” She was close behind it when she turned the corner, but the Rabbit was no longer to be seen: she found herself in a long, low hall, which was lit up by a row of lamps hanging from the roof. There seemed to be no use in waiting by the little door, so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes: this time she found a little bottle on it, (“which certainly was not here before,” said Alice,) and round the neck of the bottle was a paper label, with the words “DRINK ME,” beautifully printed on it in large letters. Let me see: that would be four thousand miles down, I think—” (for, you see, Alice had learnt several things of this sort in her lessons in the schoolroom, and though this was not a _very_ good opportunity for showing off her knowledge, as there was no one to listen to her, still it was good practice to say it over) “—yes, that’s about the right distance—but then I wonder what Latitude or Longitude I’ve got to?” (Alice had no idea what Latitude was, or Longitude either, but thought they were nice grand words to say.) Which way?”, holding her hand on the top of her head to feel which way it was growing, and she was quite surprised to find that she remained the same size: to be sure, this generally happens when one eats cake, but Alice had got so much into the way of expecting nothing but out-of-the-way things to happen, that it seemed quite dull and stupid for life to go on in the common way. “Come, there’s no use in crying like that!” said Alice to herself, rather sharply; “I advise you to leave off this minute!” She generally gave herself very good advice, (though she very seldom followed it), and sometimes she scolded herself so severely as to bring tears into her eyes; and once she remembered trying to box her own ears for having cheated herself in a game of croquet she was playing against herself, for this curious child was very fond of pretending to be two people. “No, I’ll look first,” she said, “and see whether it’s marked ‘_poison_’ or not”; for she had read several nice little histories about children who had got burnt, and eaten up by wild beasts and other unpleasant things, all because they _would_ not remember the simple rules their friends had taught them: such as, that a red-hot poker will burn you if you hold it too long; and that if you cut your finger _very_ deeply with a knife, it usually bleeds; and she had never forgotten that, if you drink much from a bottle marked “poison,” it is almost certain to disagree with you, sooner or later. She took down a jar from one of the shelves as she passed; it was labelled “ORANGE MARMALADE”, but to her great disappointment it was empty: she did not like to drop the jar for fear of killing somebody underneath, so managed to put it into one of the cupboards as she fell past it. First, she tried to look down and make out what she was coming to, but it was too dark to see anything; then she looked at the sides of the well, and noticed that they were filled with cupboards and book-shelves; here and there she saw maps and pictures hung upon pegs.\n"
     ]
    }
   ],
   "source": [
    "def text_rank(text, num_sentences=10):\n",
    "    # Tokenizar el texto\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    \n",
    "    summarizer = TextRankSummarizer()\n",
    "    \n",
    "    # Obtener las calificaciones de las oraciones\n",
    "    ratings = summarizer.rate_sentences(parser.document)\n",
    "    \n",
    "    # Ordenar las oraciones en función de sus calificaciones\n",
    "    sorted_sentences = sorted(ratings, key=lambda x: -ratings[x])\n",
    "    \n",
    "    # Seleccionar las mejores oraciones\n",
    "    top_sentences = sorted_sentences[:num_sentences]\n",
    "\n",
    "    # Imprimir las mejores oraciones como lista\n",
    "    \"\"\"print(\"Mejores oraciones:\")\n",
    "    for i, sentence in enumerate(top_sentences, 1):\n",
    "        print(f\"{i}. {sentence}\")\"\"\"\n",
    "    \n",
    "    # Construir el resumen con las mejores oraciones\n",
    "    summarized_text = \" \".join(str(sentence) for sentence in top_sentences)\n",
    "    \n",
    "    # Imprimir el resumen\n",
    "    print(\"Resumen:\")\n",
    "    print(summarized_text)\n",
    "\n",
    "\n",
    "text_rank(resultado.group(0))\n",
    "print(\"\\n\")\n",
    "text_rank(resultado2.group(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Resumen con LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen:\n",
      "Some years ago—never mind how long precisely—having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of the world.\n",
      "With a philosophical flourish Cato throws himself upon his sword; I quietly take to the ship.\n",
      "Deep into distant woodlands winds a mazy way, reaching to overlapping spurs of mountains bathed in their hill-side blue.\n",
      "Were Niagara but a cataract of sand, would you travel your thousand miles to see it?\n",
      "Why did the poor poet of Tennessee, upon suddenly receiving two handfuls of silver, deliberate whether to buy him a coat, which he sadly needed, or invest his money in a pedestrian trip to Rockaway Beach?\n",
      "For my part, I abominate all honorable respectable toils, trials, and tribulations of every kind whatsoever.\n",
      "And as for going as cook,—though I confess there is considerable glory in that, a cook being a sort of officer on ship-board—yet, somehow, I never fancied broiling fowls;—though once broiled, judiciously buttered, and judgmatically salted and peppered, there is no one who will speak more respectfully, not to say reverentially, of a broiled fowl than I will.\n",
      "The urbane activity with which a man receives money is really marvellous, considering that we so earnestly believe money to be the root of all earthly ills, and that on no account can a monied man enter heaven.\n",
      "It came in as a sort of brief interlude and solo between more extensive performances.\n",
      "Not ignoring what is good, I am quick to perceive a horror, and could still be social with it—would they let me—since it is but well to be on friendly terms with all the inmates of the place one lodges in.\n",
      "\n",
      "\n",
      "Resumen:\n",
      "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, “and what is the use of a book,” thought Alice “without pictures or conversations?”\n",
      "“Well!” thought Alice to herself, “after such a fall as this, I shall think nothing of tumbling down stairs!\n",
      "Let me see: that would be four thousand miles down, I think—” (for, you see, Alice had learnt several things of this sort in her lessons in the schoolroom, and though this was not a _very_ good opportunity for showing off her knowledge, as there was no one to listen to her, still it was good practice to say it over) “—yes, that’s about the right distance—but then I wonder what Latitude or Longitude I’ve got to?” (Alice had no idea what Latitude was, or Longitude either, but thought they were nice grand words to say.)\n",
      "How funny it’ll seem to come out among the people that walk with their heads downward!\n",
      "But do cats eat bats, I wonder?” And here Alice began to get rather sleepy, and went on saying to herself, in a dreamy sort of way, “Do cats eat bats?\n",
      "How she longed to get out of that dark hall, and wander about among those beds of bright flowers and those cool fountains, but she could not even get her head through the doorway; “and even if my head would go through,” thought poor Alice, “it would be of very little use without my shoulders.\n",
      "“No, I’ll look first,” she said, “and see whether it’s marked ‘_poison_’ or not”; for she had read several nice little histories about children who had got burnt, and eaten up by wild beasts and other unpleasant things, all because they _would_ not remember the simple rules their friends had taught them: such as, that a red-hot poker will burn you if you hold it too long; and that if you cut your finger _very_ deeply with a knife, it usually bleeds; and she had never forgotten that, if you drink much from a bottle marked “poison,” it is almost certain to disagree with you, sooner or later.\n",
      "I wonder what I should be like then?” And she tried to fancy what the flame of a candle is like after the candle is blown out, for she could not remember ever having seen such a thing.\n",
      "After a while, finding that nothing more happened, she decided on going into the garden at once; but, alas for poor Alice!\n",
      "Soon her eye fell on a little glass box that was lying under the table: she opened it, and found in it a very small cake, on which the words “EAT ME” were beautifully marked in currants.\n"
     ]
    }
   ],
   "source": [
    "def lsa_summarizer(text, num_sentences=10):\n",
    "    # Tokenizar el texto\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    \n",
    "    summarizer = LsaSummarizer()\n",
    "\n",
    "    # Crear el resumen\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "    # Imprimir el resumen\n",
    "    print(\"Resumen:\")\n",
    "    for sentence in summary:\n",
    "        print(sentence) \n",
    "    \n",
    "\n",
    "\n",
    "lsa_summarizer(resultado.group(0))\n",
    "print(\"\\n\")\n",
    "lsa_summarizer(resultado2.group(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
